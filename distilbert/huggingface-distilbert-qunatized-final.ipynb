{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "huggingface-bert.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KljpE8gRG2mm"
      },
      "source": [
        "# https://github.com/onnx/tensorflow-onnx/blob/master/tutorials/huggingface-bert.ipynb\n",
        "# https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/notebooks/bert/Bert-GLUE_OnnxRuntime_quantization.ipynb"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk72uSN5dm-K"
      },
      "source": [
        "# Converting a Huggingface model to ONNX with tf2onnx\n",
        "\n",
        "This is a simple example how to convert a [huggingface](https://huggingface.co/) model to ONNX using [tf2onnx](https://github.com/onnx/tensorflow-onnx).\n",
        "\n",
        "We use the [TFBertForQuestionAnswering](https://huggingface.co/transformers/model_doc/bert.html#tfbertforquestionanswering) example from huggingface.\n",
        "\n",
        "Other models will work similar. You'll find additional examples for other models in our unit tests [here](https://github.com/onnx/tensorflow-onnx/blob/master/tests/huggingface.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l-m7VrHdm-N"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyEVYvR2dm-N",
        "outputId": "761401cd-64af-4bc4-f601-e1ef097f744d"
      },
      "source": [
        "!pip install tensorflow transformers tf2onnx onnxruntime"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.7/dist-packages (1.9.3)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.10.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe5fCKqJdm-P"
      },
      "source": [
        "## The keras code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jto-Lbgxdm-P"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import onnxruntime as rt\n",
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification, TFDistilBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from tokenizers import BertWordPieceTokenizer"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOOmfGhSgVX-"
      },
      "source": [
        "from os import environ\n",
        "from psutil import cpu_count\n",
        "\n",
        "# Constants from the performance optimization available in onnxruntime\n",
        "# It needs to be done before importing onnxruntime\n",
        "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
        "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mA1qKoHFAim",
        "outputId": "f59d217d-beeb-4157-f24d-b9943e8984a2"
      },
      "source": [
        "! wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\n",
        "\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 08:38:53--  https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.83.198\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.83.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231508 (226K) [text/plain]\n",
            "Saving to: ‘bert-base-uncased-vocab.txt.1’\n",
            "\n",
            "bert-base-uncased-v 100%[===================>] 226.08K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-12-07 08:38:53 (2.76 MB/s) - ‘bert-base-uncased-vocab.txt.1’ saved [231508/231508]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVsUEtFaDwmv",
        "outputId": "8e048fb5-3379-4ada-a769-967133f28fac"
      },
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_39']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r-GjXLYE_xh"
      },
      "source": [
        "# text = \"\"\"\n",
        "# Voted Boston Globe\\s 2018 best New England beach town! Narragansett is the perfect seaside community for a laid back coastal retreat. Immaculate, highly ranked by VRBO, 4+ bedroom three and a half bath Pottery Barn inspired shingle style beach home designed for families and entertaining. Main part of the house has four bedrooms two and a half baths with an outdoor shower and changing room. Additionally, there is a large, finished lower level GUEST SUITE with a kitchenette, fourth bathroom and queen sized bed in the sleeping area. Perfect for family getaways, reunions, anniversaries, graduations. and local wedding accommodations. Comfortable for as little as 4 to as many as 12.\\n \\n\\nThe Harbour Island community is set on a peninsula that jets out into the salt pond. Enjoy barbecuing on our expanded deck leading onto one of the largest back yards on the island, or simply walk to kayaking, clamming, and paddle boarding on Point Judith.\\n\\nOur property is surrounded by four of Narragansett‚Äôs finest beaches just minutes away, and just up the street form a quaint private association beach/swim area (dock is for members only). Close to restaurants, shopping, Block Island ferry, and the center of town. Available primarily in the summer months weekly, monthly, or seasonally with advanced notice. \\n\\n*** HOUSE AMENITIES ***\\n\\nTwo Story Lofted Great Room, Central AC, WiFi, Custom Kitchen, Stainless Steel Appliances, Stunning Guest Suite With Private Bath and Kitchenette, Outdoor Dining Area, Large Yard, Gas Fire Pit With Seating, Weber Grill, Quality Pots and Pans, Keurig and Conventional Coffee, Mosquito and Tick Controlled, Stone Patio, Hammock, Front Porch, Multiple TV\\s, Outdoor Shower/Changing Area, Town Beach Passes, Walk to Private Quaint Association Beach (Dock is For Members Only), Off Street Parking For Up To Six Cars, Walk To Paddle Boarding, Kayaking, Clamming and Sunsets\\n\\nImmaculate, 3,000 sq/ft Pottery Barn inspired beach house... Featured in the style section of \"SO RI\" magazine! Centrally located on Harbour Island. Four bedrooms with additional lower level Guest Suite for accommodating even more guests. Open floor plan for entertaining, custom kitchen, huge yard for grilling and relaxing, central AC, deck, loft, outdoor shower, stone patio, close to beaches, kayaking,paddle boarding, B. I. ferry, shopping, & restaurants.\\n\\nAbout the area...\\nHarbour Island is centrally located in Narragansett. Our private Association Beach and swim area is just down the street from our front door (dock is for members only). It\\s a great place to take a dip, catch some sun, or launch a kayak or paddle board. Narragansett Town beach passes provided...Sand Hill Cove, Galilee, Scarborough Beach, and the Block Island ferry are all within 2.5 to 4 miles of the property. Harbour Island is close to shops, restaurants, center of town, and market yet you feel like your in a quaint coastal setting. Newport, Providence, and Foxwoods casino are all short drives away.\\nAbout the home...We have one of the largest yards on the island for grilling and relaxing with a new expanded patio and fire pit off our main deck so there is plenty of room for the whole gang! Home was built by owner to entertain with a wide open floor plan, lofted great room w/ 20 foot ceilings, top of the line kitchen, central air, porch, deck, custom built-ins, fire pit and distant water views from upper level. There is an emphasis on open, airy, light filled rooms.\\nMain part of the home has four bedrooms two and one half baths, and a hot and cold outdoor shower with changing room. Additionally, there is a large family room with fifth queen bed, fourth bath, microwave and fridge in the lower level to accommodate even more guests. Comfortable for as little as 4 to as many as 12. We have many returning guests year after...We do our best to make your stay as comfortable as possible providing incidentals such as stainless cookware, blankets, comforters, pillows, beach towels, bath towels, lawn chairs, lawn games, trash bags, spare propane for Weber grill, laundry/dish detergent, etc. Fresh sheets and pillow cases arrive at your front door from Vacation Beach House Linens the day of your arrival. Smaller, hypoallergenic pets will be considered only after speaking with host.\t\n",
        "# \"\"\"\n",
        "text=\"\"\"\n",
        "Just one block to the sand & surf at Venice Beach. Two blocks from shopping & dining on Abbot Kinney Blvd. Charming, historic, ground floor in duplex with three bedrooms. The main level features: one bathroom with shower, kitchen, dining room, living room, large entry with desk, and two bedrooms (full beds). With a staircase off the dining area, the lower level opens to sleeping area (king bed).\\n\\nThe outdoor patio is shared with the upper unit.\\n\\nHost lives full time in the upper unit. I am available if needed, please let me know\\n\\nThis is a ground floor flat with some stairs\\n\\nIf driving, please be aware of parking restrictions and street cleaning, as posted.\\n\\nBike rentals available at the beach\\n\\nBird/Lime/Jump scooters are plentiful in the area\\n\\nThis unit is street parking only. Please be aware of parking restrictions and street cleaning; there are signs posted on every block. Right outside the home, both non-metered metered street parking is available on a first come, first served basis. Meters are free after 6 PM. In addition there are several daily paid lots nearby. Feel free to search online for area paid lots, if curious (ZIP code 90291). Parking in this tourist destination is limited and in high demand.\\n\\nPublic transportation is nearby to take you to all LA has to offer\t\n",
        "\"\"\"\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H61t12zYvalM",
        "outputId": "84b591a1-6c8e-43b5-a245-d158a8965586"
      },
      "source": [
        "%%timeit\n",
        "predict_input = tokenizer.encode(text,\n",
        "                                 truncation=True,\n",
        "                                 padding=True,\n",
        "                                 return_tensors=\"tf\")\n",
        "tf_output = model.predict(predict_input)[0]\n",
        "# print(\"tf_output:  \", tf_output)\n",
        "tf_prediction = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
        "# print(\"tf_prediction: \",  tf_prediction)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.13 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 573 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY6c_qq9dm-R"
      },
      "source": [
        "## Convert to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48S_C9pydm-S"
      },
      "source": [
        "# describe the inputs\n",
        "input_spec = (\n",
        "    tf.TensorSpec((None,  None), tf.int32, name=\"input_ids\"),\n",
        ")\n",
        "\n",
        "# and convert\n",
        "_, _ = tf2onnx.convert.from_keras(model, input_signature=input_spec, opset=13, output_path=\"distilbert.onnx\")"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjB_WsvkIsTM",
        "outputId": "2b436f23-d48a-4fd3-f9e1-3b8cccce2363"
      },
      "source": [
        "!du -hs /content/distilbert.onnx"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256M\t/content/distilbert.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A46JoDnjz6Mu"
      },
      "source": [
        "# **Dynamic quantization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqIuxPjvs_fp"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions, get_all_providers\n",
        "from contextlib import contextmanager\n",
        "\n",
        "def create_model_for_provider(model_path: str, provider: str) -> InferenceSession: \n",
        "  \n",
        "  assert provider in get_all_providers(), f\"provider {provider} not found, {get_all_providers()}\"\n",
        "\n",
        "  # Few properties that might have an impact on performances (provided by MS)\n",
        "  options = SessionOptions()\n",
        "  options.intra_op_num_threads = 1\n",
        "  options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "  # Load the model as a graph and prepare the CPU backend \n",
        "  session = InferenceSession(model_path, options, providers=[provider])\n",
        "  session.disable_fallback()\n",
        "    \n",
        "  return session\n",
        "\n",
        "@contextmanager\n",
        "def track_infer_time(buffer: [int]):\n",
        "    start = time()\n",
        "    yield\n",
        "    end = time()\n",
        "\n",
        "    buffer.append(end - start)\n",
        "\n",
        "@dataclass\n",
        "class OnnxInferenceResult:\n",
        "  model_inference_time: [int]  \n",
        "  optimized_model_path: str\n",
        "\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"distilbert-base-cased\")\n",
        "# cpu_model = create_model_for_provider(\"distilbert.onnx\", \"CPUExecutionProvider\")\n",
        "\n",
        "\n",
        "#"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJamX_Zg1kzx"
      },
      "source": [
        "# Inputs are provided through numpy array\n",
        "model_inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "inputs_onnx = {k: v.cpu().detach().numpy().astype(np.int8) for k, v in model_inputs.items()}\n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "JqhkK5wHxQvG",
        "outputId": "782ae082-9286-4c7d-cca3-87f91b832864"
      },
      "source": [
        "inputs_onnx.pop('token_type_ids')\n",
        "inputs_onnx.pop('attention_mask')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-67552f64886c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minputs_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'token_type_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHlDcIf2IaX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Q8JYeVtF-X",
        "outputId": "46de15f3-3f4f-4285-ff68-c4264086b6ee"
      },
      "source": [
        "from transformers.convert_graph_to_onnx import quantize\n",
        "from pathlib import Path\n",
        "from tqdm import trange\n",
        "from dataclasses import dataclass\n",
        "from time import time\n",
        "\n",
        "# Transformers allow you to easily convert float32 model to quantized int8 with ONNX Runtime\n",
        "quantized_model_path = quantize(Path(\"distilbert.onnx\"))\n",
        "\n",
        "# Then you just have to load through ONNX runtime as you would normally do\n",
        "quantized_model = create_model_for_provider(quantized_model_path.as_posix(), \"CPUExecutionProvider\")\n",
        "\n",
        "# Warm up the overall model to have a fair comparaison\n",
        "# outputs = quantized_model.run(None, inputs_onnx)\n",
        "\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:onnxruntime.quantization.quantize is deprecated.\n",
            "         Please use quantize_static for static quantization, quantize_dynamic for dynamic quantization.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of onnxruntime 1.4.0, models larger than 2GB will fail to quantize due to protobuf constraint.\n",
            "This limitation will be removed in the next release of onnxruntime.\n",
            "Quantized model has been written at distilbert-quantized.onnx: ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWQy_QpR9aT1"
      },
      "source": [
        "text=\"\"\"\n",
        "Just one block to the sand & surf at Venice Beach. Two blocks from shopping & dining on Abbot Kinney Blvd. Charming, historic, ground floor in duplex with three bedrooms. The main level features: one bathroom with shower, kitchen, dining room, living room, large entry with desk, and two bedrooms (full beds). With a staircase off the dining area, the lower level opens to sleeping area (king bed).\\n\\nThe outdoor patio is shared with the upper unit.\\n\\nHost lives full time in the upper unit. I am available if needed, please let me know\\n\\nThis is a ground floor flat with some stairs\\n\\nIf driving, please be aware of parking restrictions and street cleaning, as posted.\\n\\nBike rentals available at the beach\\n\\nBird/Lime/Jump scooters are plentiful in the area\\n\\nThis unit is street parking only. Please be aware of parking restrictions and street cleaning; there are signs posted on every block. Right outside the home, both non-metered metered street parking is available on a first come, first served basis. Meters are free after 6 PM. In addition there are several daily paid lots nearby. Feel free to search online for area paid lots, if curious (ZIP code 90291). Parking in this tourist destination is limited and in high demand.\\n\\nPublic transportation is nearby to take you to all LA has to offer\t\n",
        "\"\"\""
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmEpkKnm9jWH"
      },
      "source": [
        "len(text)\n",
        "opt = rt.SessionOptions()\n",
        "ort_session = rt.InferenceSession(\"distilbert-quantized.onnx\")"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0M7PGl_2Kj3",
        "outputId": "3c49f01b-4905-495c-defd-87296dd06395"
      },
      "source": [
        "%%timeit\n",
        "tokenized_text = tokenizer.encode(text,\n",
        "                                 truncation=True,\n",
        "                                 padding=True,\n",
        "                                 return_tensors=\"tf\")\n",
        "\n",
        "\"\"\"\n",
        "# Inputs are provided through numpy array\n",
        "model_inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "inputs_onnx = {k: v.cpu().detach().numpy().astype(np.int8) for k, v in model_inputs.items()}\n",
        "\n",
        "\"\"\"\n",
        "input_ids=tokenized_text\n",
        "input_dict = {\"input_ids\" : input_ids.numpy() }\n",
        "ort_session.run(None, input_dict)\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 408 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud_LGxArtGDt"
      },
      "source": [
        "# # Evaluate performances\n",
        "# time_buffer = []\n",
        "# for _ in trange(100, desc=f\"Tracking inference time on CPUExecutionProvider with quantized model\"):\n",
        "#     with track_infer_time(time_buffer):\n",
        "#         outputs = quantized_model.run(None, inputs_onnx)\n",
        "\n",
        "# # Store the result\n",
        "# results = {}\n",
        "\n",
        "# results[\"ONNX CPU Quantized\"] = OnnxInferenceResult(\n",
        "#     time_buffer, \n",
        "#     quantized_model_path\n",
        "# ) \n",
        "# results"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGA8fQKetGGV"
      },
      "source": [
        ""
      ],
      "execution_count": 116,
      "outputs": []
    }
  ]
}